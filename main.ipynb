{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%writefile Imagelib.h\n",
        "#pragma once\n",
        "#include <cstdint>\n",
        "#include <cstdio>\n",
        "#include <cstdlib>\n",
        "#include <cstring>\n",
        "#include <cassert>\n",
        "#include <iostream>\n",
        "#include <algorithm>\n",
        "#include <fstream>\n",
        "#include <string>\n",
        "#include <vector>\n",
        "#include <iomanip>\n",
        "using byte = unsigned char;\n",
        "#define LOG_OUT(_x_)\n",
        "#define LOG_OUT_W(_x_)\n",
        "#define LOG_OUT_A(_x_)\n",
        "#pragma pack(push, 1)\n",
        "typedef struct {\n",
        "    unsigned short bfType;\n",
        "    unsigned int   bfSize;\n",
        "    unsigned short bfReserved1;\n",
        "    unsigned short bfReserved2;\n",
        "    unsigned int   bfOffBits;\n",
        "} BITMAPFILEHEADER;\n",
        "\n",
        "typedef struct {\n",
        "    unsigned int   biSize;\n",
        "    int            biWidth;\n",
        "    int            biHeight;\n",
        "    unsigned short biPlanes;\n",
        "    unsigned short biBitCount;\n",
        "    unsigned int   biCompression;\n",
        "    unsigned int   biSizeImage;\n",
        "    int            biXPelsPerMeter;\n",
        "    int            biYPelsPerMeter;\n",
        "    unsigned int   biClrUsed;\n",
        "    unsigned int   biClrImportant;\n",
        "} BITMAPINFOHEADER;\n",
        "#pragma pack(pop)\n",
        "static inline uint32_t row_stride_24(int w) {\n",
        "    return (uint32_t)(((w * 3) + 3) & ~3u);\n",
        "}\n",
        "// ---- 선언 ----\n",
        "bool LoadBmp(const char* filename, byte** pImage, int& height, int& width);\n",
        "bool SaveBmp(const char* filename, byte* pImage, int height, int width);\n",
        "bool convert1Dto2D(byte* src, double** dst_Y, double** dst_U, double** dst_V, int height, int width);\n",
        "bool convert2Dto1D(double** src_Y, double** src_U, double** src_V, byte* dst, int height, int width);\n",
        "void convert2Dto3D(double **src2D, double ***dst3D, int height, int width);\n",
        "void convert3Dto2D(double ***src3D, double **dst2D, int height, int width);\n",
        "double *dmatrix1D(int nH);\n",
        "double **dmatrix2D(int nH, int nW);\n",
        "double ***dmatrix3D(int nH, int nW, int nC);\n",
        "double ****dmatrix4D(int nH, int nW, int nC, int nNum);\n",
        "void free_dmatrix1D(double *Image, int nH);\n",
        "void free_dmatrix2D(double **Image, int nH, int nW);\n",
        "void free_dmatrix3D(double ***Image, int nH, int nW, int nC);\n",
        "void free_dmatrix4D(double ****Image, int nH, int nW, int nC, int nNum);\n",
        "double clip(double x, double minVal, double maxVal);\n",
        "double** simpleUpsampling2x(double **Image, int nH, int nW);\n",
        "\n",
        "\n",
        "// ---- 정의 ----\n",
        "bool LoadBmp(const char* filename, byte** pImage, int& height, int& width) {\n",
        "    *pImage = nullptr;\n",
        "    std::FILE* fp = std::fopen(filename, \"rb\");\n",
        "    if (!fp) { LOG_OUT_A(\"fopen() error\"); return false; }\n",
        "    BITMAPFILEHEADER bmf{};\n",
        "    BITMAPINFOHEADER bmi{};\n",
        "    if (std::fread(&bmf, sizeof(bmf), 1, fp) != 1) { std::fclose(fp); return false; }\n",
        "    if (bmf.bfType != 0x4D42) { std::fclose(fp); LOG_OUT_A(\"not .bmp file\"); return false; }\n",
        "    if (std::fread(&bmi, sizeof(bmi), 1, fp) != 1) { std::fclose(fp); return false; }\n",
        "    if (bmi.biBitCount != 24 || bmi.biCompression != 0 /*BI_RGB*/) {\n",
        "        std::fclose(fp); LOG_OUT_A(\"only 24-bit BI_RGB supported\"); return false;\n",
        "    }\n",
        "    width  = bmi.biWidth;\n",
        "    height = (bmi.biHeight >= 0) ? bmi.biHeight : -bmi.biHeight;\n",
        "    const bool bottom_up = (bmi.biHeight > 0);\n",
        "    const uint32_t stride = row_stride_24(width);\n",
        "    const uint32_t data_bytes = stride * (uint32_t)height;\n",
        "    // 픽셀 데이터 위치로 이동\n",
        "    if (bmf.bfOffBits > sizeof(bmf) + sizeof(bmi)) {\n",
        "        std::fseek(fp, (long)bmf.bfOffBits, SEEK_SET);\n",
        "    }\n",
        "    // 원본(패딩 포함) 읽기\n",
        "    std::vector<unsigned char> buf(data_bytes);\n",
        "    if (std::fread(buf.data(), 1, data_bytes, fp) != data_bytes) { std::fclose(fp); return false; }\n",
        "    std::fclose(fp);\n",
        "    // 호출자용 포맷: 패딩 없음, top→bottom, BGR 연속 메모리\n",
        "    *pImage = (byte*)std::malloc((size_t)width * height * 3);\n",
        "    if (!*pImage) return false;\n",
        "    for (int y = 0; y < height; ++y) {\n",
        "        int src_y = bottom_up ? (height - 1 - y) : y;\n",
        "        const unsigned char* src = buf.data() + (size_t)src_y * stride;\n",
        "        byte* dst = *pImage + (size_t)y * width * 3;\n",
        "        std::memcpy(dst, src, (size_t)width * 3);\n",
        "    }\n",
        "    return true;\n",
        "}\n",
        "bool SaveBmp(const char* filename, byte* pImage, int height, int width) {\n",
        "    // pImage: top→bottom, 패딩 없음, BGR 연속\n",
        "    const uint32_t stride = row_stride_24(width);\n",
        "    const uint32_t data_bytes = stride * (uint32_t)height;\n",
        "    BITMAPFILEHEADER bmf{};\n",
        "    BITMAPINFOHEADER bmi{};\n",
        "    bmi.biSize = sizeof(BITMAPINFOHEADER);\n",
        "    bmi.biWidth = width;\n",
        "    bmi.biHeight = height;        // bottom-up 저장(양수)\n",
        "    bmi.biPlanes = 1;\n",
        "    bmi.biBitCount = 24;\n",
        "    bmi.biCompression = 0;        // BI_RGB\n",
        "    bmi.biSizeImage = data_bytes;\n",
        "    bmf.bfType = 0x4D42; // 'BM'\n",
        "    bmf.bfOffBits = sizeof(BITMAPFILEHEADER) + sizeof(BITMAPINFOHEADER);\n",
        "    bmf.bfSize = bmf.bfOffBits + data_bytes;\n",
        "    std::FILE* fp = std::fopen(filename, \"wb\");\n",
        "    if (!fp) { LOG_OUT_A(\"fopen() error\"); return false; }\n",
        "    std::fwrite(&bmf, 1, sizeof(bmf), fp);\n",
        "    std::fwrite(&bmi, 1, sizeof(bmi), fp);\n",
        "    std::vector<unsigned char> row(stride, 0);\n",
        "    for (int y = height - 1; y >= 0; --y) {\n",
        "        const byte* src = pImage + (size_t)y * width * 3;\n",
        "        std::memcpy(row.data(), src, (size_t)width * 3);\n",
        "        std::fwrite(row.data(), 1, stride, fp);\n",
        "    }\n",
        "    std::fclose(fp);\n",
        "    return true;\n",
        "}\n",
        "bool convert1Dto2D(byte* src, double** dst_Y, double** dst_U, double** dst_V, int height, int width) {\n",
        "    int iR, iG, iB;\n",
        "    for (int y = 0; y < height; y++) {\n",
        "        for (int x = 0; x < width; x++) {\n",
        "            iB = src[3 * width * y + 3 * x + 0];\n",
        "            iG = src[3 * width * y + 3 * x + 1];\n",
        "            iR = src[3 * width * y + 3 * x + 2];\n",
        "            dst_Y[y][x] = iR * 0.299 + iG * 0.587 + iB * 0.114;\n",
        "            dst_U[y][x] = (iB - dst_Y[y][x]) * 0.565;\n",
        "            dst_V[y][x] = (iR - dst_Y[y][x]) * 0.713;\n",
        "            dst_Y[y][x] = dst_Y[y][x] / 255.0; // [0,255] → [0,1]\n",
        "        }\n",
        "    }\n",
        "    return true;\n",
        "}\n",
        "bool convert2Dto1D(double** src_Y, double** src_U, double** src_V, byte* dst, int height, int width) {\n",
        "    int iCount = 0;\n",
        "    int iR, iG, iB;\n",
        "    for (int y = 0; y < height; y++) {\n",
        "        for (int x = 0; x < width; x++) {\n",
        "            double Y = src_Y[y][x] * 255.0;\n",
        "            iR = (int)clip(Y + 1.403 * src_V[y][x], 0, 255);\n",
        "            iG = (int)clip(Y - 0.344 * src_U[y][x] - 0.714 * src_V[y][x], 0, 255);\n",
        "            iB = (int)clip(Y + 1.770 * src_U[y][x], 0, 255);\n",
        "            dst[iCount + 0] = (byte)iB;\n",
        "            dst[iCount + 1] = (byte)iG;\n",
        "            dst[iCount + 2] = (byte)iR;\n",
        "            iCount += 3;\n",
        "        }\n",
        "    }\n",
        "    return true;\n",
        "}\n",
        "double clip(double x, double minVal, double maxVal) {\n",
        "    if (x < minVal) x = minVal;\n",
        "    if (x > maxVal) x = maxVal;\n",
        "    return x;\n",
        "}\n",
        "double** simpleUpsampling2x(double **Image, int nH, int nW) {\n",
        "    double** outImg = dmatrix2D(nH * 2, nW * 2);\n",
        "    for (int y = 0; y < nH; y++) {\n",
        "        for (int x = 0; x < nW; x++) {\n",
        "            outImg[2 * y + 0][2 * x + 0] = Image[y][x];\n",
        "            outImg[2 * y + 0][2 * x + 1] = Image[y][x];\n",
        "            outImg[2 * y + 1][2 * x + 0] = Image[y][x];\n",
        "            outImg[2 * y + 1][2 * x + 1] = Image[y][x];\n",
        "        }\n",
        "    }\n",
        "    return outImg;\n",
        "}\n",
        "double *dmatrix1D(int nH) {\n",
        "    return new double[nH]();\n",
        "}\n",
        "double **dmatrix2D(int nH, int nW) {\n",
        "    double **Temp = new double*[nH];\n",
        "    for (int y = 0; y < nH; y++) Temp[y] = new double[nW]();\n",
        "    return Temp;\n",
        "}\n",
        "double ***dmatrix3D(int nH, int nW, int nC) {\n",
        "    double ***Temp = new double**[nH];\n",
        "    for (int y = 0; y < nH; y++) {\n",
        "        Temp[y] = new double*[nW];\n",
        "        for (int x = 0; x < nW; x++) Temp[y][x] = new double[nC]();\n",
        "    }\n",
        "    return Temp;\n",
        "}\n",
        "double ****dmatrix4D(int nH, int nW, int nC, int nNum) {\n",
        "    double ****Temp = new double***[nH];\n",
        "    for (int y = 0; y < nH; y++) {\n",
        "        Temp[y] = new double**[nW];\n",
        "        for (int x = 0; x < nW; x++) {\n",
        "            Temp[y][x] = new double*[nC];\n",
        "            for (int c = 0; c < nC; c++) Temp[y][x][c] = new double[nNum]();\n",
        "        }\n",
        "    }\n",
        "    return Temp;\n",
        "}\n",
        "void free_dmatrix1D(double *Image, int) { delete[] Image; }\n",
        "void free_dmatrix2D(double **Image, int nH, int) {\n",
        "    for (int y = 0; y < nH; y++) delete[] Image[y];\n",
        "    delete[] Image;\n",
        "}\n",
        "void free_dmatrix3D(double ***Image, int nH, int nW, int) {\n",
        "    for (int y = 0; y < nH; y++) {\n",
        "        for (int x = 0; x < nW; x++) delete[] Image[y][x];\n",
        "        delete[] Image[y];\n",
        "    }\n",
        "    delete[] Image;\n",
        "}\n",
        "void free_dmatrix4D(double ****Image, int nH, int nW, int nC, int) {\n",
        "    for (int y = 0; y < nH; y++) {\n",
        "        for (int x = 0; x < nW; x++) {\n",
        "            for (int c = 0; c < nC; c++) delete[] Image[y][x][c];\n",
        "            delete[] Image[y][x];\n",
        "        }\n",
        "        delete[] Image[y];\n",
        "    }\n",
        "    delete[] Image;\n",
        "}\n",
        "void convert2Dto3D(double **src2D, double ***dst3D, int height, int width) {\n",
        "    for (int y = 0; y < height; y++)\n",
        "        for (int x = 0; x < width; x++)\n",
        "            dst3D[y][x][0] = src2D[y][x];\n",
        "}\n",
        "void convert3Dto2D(double ***src3D, double **dst2D, int height, int width) {\n",
        "    for (int y = 0; y < height; y++)\n",
        "        for (int x = 0; x < width; x++)\n",
        "            dst2D[y][x] = src3D[y][x][0];\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Os6pXvmcYvsJ",
        "outputId": "cf56e98a-e9ae-4570-a793-e6e221f1e614"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting Imagelib.h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile CTensor.h\n",
        "\n",
        "#pragma once\n",
        "#include \"Imagelib.h\"\n",
        "#include <iostream>\n",
        "#include <fstream>\n",
        "#include <stdexcept>\n",
        "#include <string>\n",
        "using std::cout;\n",
        "using std::endl;\n",
        "using std::string;\n",
        "\n",
        "// Tensor3D는 크기가 (nH x nW x nC)인 3차원 tensor를 관리함\n",
        "\n",
        "class Tensor3D {\n",
        "private:\n",
        "\tdouble*** tensor;\n",
        "\tint nH; // height\n",
        "\tint nW; // width\n",
        "\tint nC; // channel\n",
        "public:\n",
        "\tTensor3D(int _nH, int _nW, int _nC) : nH(_nH), nW(_nW), nC(_nC) {\n",
        "\t\t// (구현할 것)//////////////////////////////////////////////////////////////////////\n",
        "\t\t// 동작:\n",
        "\t\t//\n",
        "\t\t// 사용함수: dmatrix3D(): 3차원 행렬을 동적 할당해서 pointer를 반환하는 함수\n",
        "\t\ttensor = dmatrix3D(nH, nW, nC);\n",
        "\t}\n",
        "\t~Tensor3D() {\n",
        "\t\t// (구현할 것)//////////////////////////////////////////////////////////////////////\n",
        "\t\t// 동작: 3차원 동적 배열인 tensor를 할당 해제\n",
        "\t\t// 사용함수: free_dmatrix3D(): 3차원 동적 할당된 행렬을 할당 해제하는 함수\n",
        "\t\tfree_dmatrix3D(tensor, nH, nW, nC);\n",
        "\t}\n",
        "\tvoid set_elem(int _h, int _w, int _c, double _val) { tensor[_h][_w][_c] = _val; }\n",
        "\tdouble get_elem(int _h, int _w, int _c)\tconst {\n",
        "\t\t// (구현할 것)//////////////////////////////////////////////////////////////////////\n",
        "\t\t// 동작: 행=_h, 열= _w, 채널= _c 위치 element를 반환할 것\n",
        "\t\treturn tensor[_h][_w][_c];\n",
        "\t}\n",
        "\n",
        "\tvoid get_info(int& _nH, int& _nW, int& _nC) const {\n",
        "\t\t// (구현할 것)//////////////////////////////////////////////////////////////////////\n",
        "\t\t// 동작: 행렬의 차원(nH, nW, nC)을 pass by reference로 반환\n",
        "\t\t_nH = nH;\n",
        "\t\t_nW = nW;\n",
        "\t\t_nC = nC;\n",
        "\t}\n",
        "\n",
        "\tvoid set_tensor(double*** _tensor) { tensor = _tensor; }\n",
        "\tdouble*** get_tensor() const { return tensor; }\n",
        "\n",
        "\tvoid print() const {\n",
        "\t\t// (구현할 것)//////////////////////////////////////////////////////////////////////\n",
        "\t\t// 동작: 행렬의 크기 (nH*nW*nC)를 화면에 출력\n",
        "\t\tprintf(\"Tensor size: %d x %d x %d\\n\", nH, nW, nC);\n",
        "\t}\n",
        "};"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKk6uHS-FYwb",
        "outputId": "d62c115c-a079-4ac4-ec46-5cfa4918b484"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing CTensor.h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile CLayer.h\n",
        "#pragma once\n",
        "#include <iostream>\n",
        "#include <fstream>\n",
        "#include <stdexcept>\n",
        "#include <string>\n",
        "#include <omp.h>\n",
        "#include \"Imagelib.h\"\n",
        "#include \"CTensor.h\"\n",
        "#define MEAN_INIT 0\n",
        "#define LOAD_INIT 1\n",
        "using std::cout;\n",
        "using std::endl;\n",
        "using std::string;\n",
        "\n",
        "// Layer는 tensor를 입/출력으로 가지며, 특정 operation을 수행하는 Convolutional Neural Netowork의 기본 연산 단위\n",
        "\n",
        "\n",
        "class Layer {\n",
        "protected:\n",
        "\tint fK; // kernel size in K*K kernel\n",
        "\tint fC_in; // number of channels\n",
        "\tint fC_out; //number of filters\n",
        "\tstring name;\n",
        "public:\n",
        "\tLayer(string _name, int _fK, int _fC_in, int _fC_out) : name(_name), fK(_fK), fC_in(_fC_in), fC_out(_fC_out) {}\n",
        "\tvirtual ~Layer() {}; //가상소멸자 (참고: https://wonjayk.tistory.com/243)\n",
        "\tvirtual Tensor3D* forward(const Tensor3D* input) = 0;\n",
        "\t//\tvirtual bool backward() = 0;\n",
        "\tvirtual void print() const = 0;\n",
        "\tvirtual void get_info(string& _name, int& _fK, int& _fC_in, int& _fC_out) const = 0;\n",
        "};\n",
        "\n",
        "\n",
        "class Layer_ReLU : public Layer {\n",
        "public:\n",
        "\tLayer_ReLU(string _name, int _fK, int _fC_in, int _fC_out)\n",
        "\t\t: Layer(_name, _fK, _fC_in, _fC_out)\n",
        "\t{\n",
        "\t\t// (구현할 것)//////////////////////////////////////////////////////////////////////\n",
        "\t\t// 동작1: Base class의 생성자를 호출하여 맴버 변수를 초기화 할 것(반드시 initialization list를 사용할 것)\n",
        "\t}\n",
        "\t~Layer_ReLU() {}\n",
        "\tTensor3D* forward(const Tensor3D* input) override {\n",
        "\t\t// (구현할 것)\n",
        "\t\t// 동작1: input tensor에 대해 각 element x가 양수이면 그대로 전달, 음수이면 0으로 output tensor에 전달할것\n",
        "\t\t// 동작2: 이때, output tensor는 동적할당하여 주소값을 반환할 것\n",
        "\t\t// 함수1: Tensor3D의 맴버함수인 get_info(), get_elem(), set_elem()을 적절히 활용할 것\n",
        "\t\tint H, W, C;\n",
        "\t\tinput->get_info(H, W, C);\n",
        "\n",
        "\t\tTensor3D* output = new Tensor3D(H, W, C);\n",
        "\t\tfor (int h = 0; h < H; h++) {\n",
        "\t\t\tfor (int w = 0; w < W; w++) {\n",
        "\t\t\t\tfor (int c = 0; c < C; c++) {\n",
        "\t\t\t\t\tdouble val = input->get_elem(h, w, c);\n",
        "\t\t\t\t\toutput->set_elem(h, w, c, (val > 0) ? val : 0.0);\n",
        "\t\t\t\t}\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t\tcout << name << \" is finished\" << endl;\n",
        "\t\treturn output;\n",
        "\t};\n",
        "\tvoid get_info(string& _name, int& _fK, int& _fC_in, int& _fC_out) const override {\n",
        "\t\t// (구현할 것)//////////////////////////////////////////////////////////////////////\n",
        "\t\t// 동작: Tensor3D의 get_info()와 마찬가지로 맴버 변수들을 pass by reference로 외부에 전달\n",
        "\t\t_name = name;\n",
        "\t\t_fK = fK;\n",
        "\t\t_fC_in = fC_in;\n",
        "\t\t_fC_out = fC_out;\n",
        "\t}\n",
        "\tvoid print() const override {\n",
        "\t\t// (구현할 것)//////////////////////////////////////////////////////////////////////\n",
        "\t\t// 동작: Tensor3D의 print()와 마찬가지로 차원의 크기를 화면에 출력\n",
        "\t\tcout << \"Layer: \" << name << \" (ReLU) \"\n",
        "\t\t\t<< \"Kernel=\" << fK\n",
        "\t\t\t<< \" Cin=\" << fC_in\n",
        "\t\t\t<< \" Cout=\" << fC_out << endl;\n",
        "\t}\n",
        "};\n",
        "\n",
        "\n",
        "\n",
        "class Layer_Conv : public Layer {\n",
        "private:\n",
        "\tstring filename_weight;\n",
        "\tstring filename_bias;\n",
        "\tdouble**** weight_tensor; // fK x fK x _fC_in x _fC_out 크기를 가지는 4차원 배열\n",
        "\tdouble*  bias_tensor;     // _fC_out 크기를 가지는 1차원 배열 (bias는 각 filter당 1개 존재)\n",
        "public:\n",
        "\tLayer_Conv(string _name, int _fK, int _fC_in, int _fC_out, int init_type, string _filename_weight = \"\", string _filename_bias = \"\")\n",
        "\t:Layer(_name, _fK, _fC_in, _fC_out),\n",
        "          filename_weight(_filename_weight), filename_bias(_filename_bias)\n",
        "\t{\n",
        "\t\t// (구현할 것)//////////////////////////////////////////////////////////////////////\n",
        "\t\t// 동작1: initialization list와 base class의 생성자를 이용하여 맴버 변수를 초기화 할 것\n",
        "\t\t// 동작2: filename_weight와 filename_bias는 LOAD_INIT 모드일 경우 해당 파일로부터 가중치/바이어스를 불러옴\n",
        "\t\t// 동작3: init() 함수는 init_type를 입력으로 받아 가중치를 초기화 함\n",
        "\t\t// 함수1: dmatrix4D()와 dmatrix1D()를 사용하여 1차원, 4차원 배열을 동적 할당할 것\n",
        "\t\tweight_tensor = dmatrix4D(fK, fK, fC_in, fC_out);\n",
        "\t\tbias_tensor = dmatrix1D(fC_out);\n",
        "\n",
        "\n",
        "\t\tinit(init_type);\n",
        "\t}\n",
        "\tvoid init(int init_type) {\n",
        "\t\t// (구현할 것)//////////////////////////////////////////////////////////////////////\n",
        "\t\t// 동작1: init_type (MEAN_INIT 또는 LOAD_INIT)에 따라 가중치를 다른 방식으로 초기화 함\n",
        "\t\t// 동작2: MEAN_INIT의 경우 필터는 평균값을 산출하는 필터가 됨 (즉, 모든 가중치 값이 필터의 크기(fK*fK*fC_in)의 역수와 같아짐 (이때 bias는 모두 0으로 설정)\n",
        "\t\t// 동작3: LOAD_INIT의 경우 filename_weight, filename_bias의 이름을 가지는 파일의 값을 읽어 가중치에 저장(초기화) 함\n",
        "\t\t// 함수1: dmatrix4D()와 dmatrix1D()를 사용하여 1차원, 4차원 배열을 동적 할당할 것\n",
        "\t\tif (init_type == MEAN_INIT) {\n",
        "\t\t\tdouble val = 1.0 / (fK * fK * fC_in);\n",
        "\t\t\tfor (int y = 0; y < fK; y++) {\n",
        "\t\t\t\tfor (int x = 0; x < fK; x++) {\n",
        "\t\t\t\t\tfor (int c = 0; c < fC_in; c++) {\n",
        "\t\t\t\t\t\tfor (int n = 0; n < fC_out; n++) {\n",
        "\t\t\t\t\t\t\tweight_tensor[y][x][c][n] = val;\n",
        "\t\t\t\t\t\t}\n",
        "\t\t\t\t\t}\n",
        "\t\t\t\t}\n",
        "\t\t\t}\n",
        "\t\t\tfor (int n = 0; n < fC_out; n++) bias_tensor[n] = 0.0;\n",
        "\t\t}\n",
        "\t\telse if (init_type == LOAD_INIT) {\n",
        "\t\tstd::ifstream weight_file(filename_weight);\n",
        "        if (!weight_file.is_open()) {\n",
        "            // 파일 열기 실패 시 에러 메시지 출력 후 프로그램 종료\n",
        "            std::cerr << \"Error: Could not open weight file: \" << filename_weight << std::endl;\n",
        "            exit(EXIT_FAILURE);\n",
        "        }\n",
        "\n",
        "        std::cout << \"Loading weights from \" << filename_weight << \"...\" << std::endl;\n",
        "        for (int y = 0; y < fK; y++) {\n",
        "            for (int x = 0; x < fK; x++) {\n",
        "                for (int c = 0; c < fC_in; c++) {\n",
        "                    for (int n = 0; n < fC_out; n++) {\n",
        "                        // 파일에서 double 값을 하나씩 읽어와 텐서에 저장\n",
        "                        weight_file >> weight_tensor[y][x][c][n];\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "        weight_file.close(); // 파일 닫기\n",
        "\n",
        "        // 2. Bias Tensor 불러오기\n",
        "        std::ifstream bias_file(filename_bias);\n",
        "        if (!bias_file.is_open()) {\n",
        "            std::cerr << \"Error: Could not open bias file: \" << filename_bias << std::endl;\n",
        "            exit(EXIT_FAILURE);\n",
        "        }\n",
        "\n",
        "        std::cout << \"Loading biases from \" << filename_bias << \"...\" << std::endl;\n",
        "        for (int n = 0; n < fC_out; n++) {\n",
        "            bias_file >> bias_tensor[n];\n",
        "        }\n",
        "        bias_file.close();}\n",
        "\t}\n",
        "\t~Layer_Conv() override {\n",
        "\t\t// (구현할 것)//////////////////////////////////////////////////////////////////////\n",
        "\t\t// 동작1: weight_tensor와 bias_tensor를 동적 할당 해제할 것\n",
        "\t\t// 함수1: free_dmatrix4D(), free_dmatrix1D() 함수를 사용\n",
        "\t\tfree_dmatrix4D(weight_tensor, fK, fK, fC_in, fC_out);\n",
        "\t\tfree_dmatrix1D(bias_tensor, fC_out);\n",
        "\t}\n",
        "\tTensor3D* forward(const Tensor3D* input) override {\n",
        "\t\t// (구현할 것)//////////////////////////////////////////////////////////////////////\n",
        "\t\t// 동작1: 컨볼루션 (각 위치마다 y = WX + b)를 수행\n",
        "\t\t// 동작2: output (Tensor3D type)를 먼저 동적 할당하고 연산이 완료된 다음 pointer를 반환\n",
        "\t\tint H, W, C;\n",
        "\t\tinput->get_info(H, W, C);\n",
        "\t\tassert(C == fC_in); // 입력 채널이 일치해야 함\n",
        "\n",
        "\t\t// 1. 'Same Padding'을 위한 패딩 값 계산\n",
        "\t// 3x3 커널일 경우 pad = 1, 5x5 커널일 경우 pad = 2\n",
        "\t\tint pad = fK / 2;\n",
        "\n",
        "\t\t// 2. 출력 텐서의 크기는 입력과 동일하게 설정\n",
        "\t\tint outH = H;\n",
        "\t\tint outW = W;\n",
        "\n",
        "\t\tTensor3D* output = new Tensor3D(outH, outW, fC_out);\n",
        "\n",
        "\t\t// 출력 텐서의 모든 픽셀(oh, ow)에 대해 연산\n",
        "\t\t#pragma omp parallel for collapse(3) schedule(dynamic)\n",
        "\t\tfor (int oh = 0; oh < outH; oh++) {\n",
        "\t\t\t\tfor (int ow = 0; ow < outW; ow++) {\n",
        "\t\t\t\t\t\tfor (int f = 0; f < fC_out; f++) {\n",
        "\t\t\t\t\t\t\t\tdouble sum = 0.0;\n",
        "\t\t\t\t\t\t\t\tfor (int kh = 0; kh < fK; kh++) {\n",
        "\t\t\t\t\t\t\t\t\t\tfor (int kw = 0; kw < fK; kw++) {\n",
        "\t\t\t\t\t\t\t\t\t\t\t\tfor (int c = 0; c < fC_in; c++) {\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tint ih = oh + kh - pad;\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tint iw = ow + kw - pad;\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\tif (ih >= 0 && ih < H && iw >= 0 && iw < W) {\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdouble val = input->get_elem(ih, iw, c);\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tsum += val * weight_tensor[kh][kw][c][f];\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t}\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t}\n",
        "\t\t\t\t\t\t\t\t\t\t}\n",
        "\t\t\t\t\t\t\t\t}\n",
        "\t\t\t\t\t\t\t\tsum += bias_tensor[f];\n",
        "\t\t\t\t\t\t\t\toutput->set_elem(oh, ow, f, sum);\n",
        "\t\t\t\t\t\t}\n",
        "\t\t\t\t}\n",
        "\t\t}\n",
        "\t\tcout  << name << \" is finished\" << endl;\n",
        "\t\treturn output;\n",
        "\t};\n",
        "\tvoid get_info(string& _name, int& _fK, int& _fC_in, int& _fC_out) const override {\n",
        "\t\t// (구현할 것)//////////////////////////////////////////////////////////////////////\n",
        "\t\t// 동작: Layer_ReLU와 동일\n",
        "\t\t_name = name;\n",
        "\t\t_fK = fK;\n",
        "\t\t_fC_in = fC_in;\n",
        "\t\t_fC_out = fC_out;\n",
        "\t}\n",
        "\tvoid print() const override {\n",
        "\t\t// (구현할 것)//////////////////////////////////////////////////////////////////////\n",
        "\t\t// 동작: Layer_ReLU와 동일\n",
        "\t\tcout << \"Layer: \" << name << \" (Conv) \"\n",
        "\t\t\t<< \"Kernel=\" << fK\n",
        "\t\t\t<< \" Cin=\" << fC_in\n",
        "\t\t\t<< \" Cout=\" << fC_out << endl;\n",
        "\t}\n",
        "};\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_C6euwWFgEl",
        "outputId": "7c351037-bf84-4e89-a0a8-3dba2c2e09d8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing CLayer.h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile CModel.h\n",
        "#pragma once\n",
        "#include <vector>\n",
        "#include <string>\n",
        "#include <iostream>\n",
        "#include <iomanip>\n",
        "#include \"CLayer.h\"\n",
        "using std::vector;\n",
        "using std::string;\n",
        "using std::cout;\n",
        "\n",
        "using std::endl;\n",
        "using std::setw;\n",
        "\n",
        "// Model은 layer와 tensor들을 모두 통합 관리하여 효과적으로 CNN이 수행될 수 있도록 함\n",
        "\n",
        "class Model {\n",
        "private:\n",
        "\tvector<Layer*> layers; //layer들을 순차적으로 저장\n",
        "\tvector<Tensor3D*> tensors;// tensor들을 순차적으로 저장 ( 0번째 tensor는 0번째 layer의 입력, 마찬가지로 1번째 tensor는 1번째 layer의 입력이자 0번째 layer의 출력임)\n",
        "public:\n",
        "\tModel() {}\n",
        "\tvoid add_layer(Layer* layer) {\n",
        "\t\t// (구현할 것) //////////////////////////////////////////////////\n",
        "\t\t// 동작: layer 객체를 layers vector의 마지막 element로 저장\n",
        "\t\tlayers.push_back(layer);\n",
        "\t}\n",
        "\t~Model() {\n",
        "\t\t// (구현할 것)//////////////////////////////////////////////////\n",
        "\t\t// 동작: layers와 tensors의 모든 element를 동적할당 해제해 줄 것\n",
        "\t\tfor (auto& l : layers) {\n",
        "\t\t\tdelete l;\n",
        "\t\t}\n",
        "\t\tlayers.clear();\n",
        "\n",
        "\t\tfor (auto& t : tensors) {\n",
        "\t\t\tdelete t;\n",
        "\t\t}\n",
        "\t\ttensors.clear();\n",
        "\t}\n",
        "\tvoid test(string filename_input, string filename_output) {\n",
        "\t\t// (구현할 것)//////////////////////////////////////////////////\n",
        "\t\t// 동작1: filename_input으로부터 이미지를 읽어와서, tensor로 변환한 다음 CNN을 수행한다음 그 결과물을 filename_output에 저장\n",
        "\t\t// 동작2: 주석 (1), (2), (3), (4) 중 (2)번만 구현하면 됨\n",
        "\n",
        "\t\tint nH, nW;\n",
        "\t\tdouble** input_img_Y, **input_img_U, **input_img_V;\n",
        "\t\tbyte* pLoadImage;\n",
        "\n",
        "\t\t// (1) 영상을 읽어서 2차원 배열로 저장 (input_img_Y, U, V는 read_image에서 동적 할당됨)\n",
        "\t\tread_image(filename_input, pLoadImage, input_img_Y, input_img_U, input_img_V, nH, nW);\n",
        "\t\tcout << \"Reading (\" << filename_input << \") is complete...\" << endl;\n",
        "\n",
        "\n",
        "\t\t// (2) 이부분만 구현할 것//////////////////////////////////////////////////\n",
        "\t\t// 동작1: 현재 tensors의 0번째 element에 영상(CNN의 입력)이 이미 저장되어 있음\n",
        "\t\t// 동작2: tensors vector의 i번째 tensor를 layers vector에 있는 i번째 layer의 forward함수로 입력받고, 그 결과를 tensors vector의 i+1번째 tensor로 저장함\n",
        "\t\t// 동작3: 결과적으로 tensors의 가장 마지막 tensor는 CNN의 출력값이 됨 (이 출력값은 (3)에서 1차원 배열로 변환되어 이미지 파일에 저장됨\n",
        "\t\tfor (size_t i = 0; i < layers.size(); i++) {\n",
        "\t\t\tTensor3D* input_tensor = tensors.at(i);            // i번째 tensor를 입력으로\n",
        "\t\t\tTensor3D* output_tensor = layers.at(i)->forward(input_tensor); // layer forward\n",
        "\t\t\ttensors.push_back(output_tensor);                  // i+1번째 tensor로 추가\n",
        "\n",
        "\t\t}\n",
        "\t\tTensor3D* input_tensor = tensors.at(0);\n",
        "\t\tTensor3D* residual_tensor = tensors.at(tensors.size() - 1);\n",
        "\n",
        "\t\tint H, W, C;\n",
        "\t\tinput_tensor->get_info(H, W, C);\n",
        "\n",
        "\t\t// 최종 결과를 저장할 새로운 텐서를 생성\n",
        "\t\tTensor3D* final_image_tensor = new Tensor3D(H, W, C);\n",
        "\n",
        "\t\tfor (int h = 0; h < H; h++) {\n",
        "\t\t\tfor (int w = 0; w < W; w++) {\n",
        "\t\t\t\tdouble input_val = input_tensor->get_elem(h, w, 0);\n",
        "\t\t\t\tdouble residual_val = residual_tensor->get_elem(h, w, 0);\n",
        "\t\t\t\t// 원본 + 차이 값 = 최종 결과\n",
        "\t\t\t\tfinal_image_tensor->set_elem(h, w, 0, input_val + residual_val);\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t\t// 완성된 최종 이미지를 텐서 목록의 맨 뒤에 추가\n",
        "\t\ttensors.push_back(final_image_tensor);\n",
        "\n",
        "\t\tcout << \"Super-resolution is complete...\" << endl;\n",
        "\n",
        "\t\tcout << \"2\";\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\t\t// (3) CNN의 출력(마지막 tensor)을 2차원 배열로 변환 후 U, V 채널과 함께 이미지로 저장\n",
        "\t\tTensor3D* output_tensor_Y = tensors.at(tensors.size() - 1);\n",
        "\t\toutput_tensor_Y->print();\n",
        "\t\tsave_image(filename_output, pLoadImage, output_tensor_Y, input_img_U, input_img_V, nH, nW);\n",
        "\t\tcout << \"Saving (\" << filename_output << \") is complete...\" << endl;\n",
        "\n",
        "\t\tcout << \"3\";\n",
        "\n",
        "\t\t// (4) 할당 해제\n",
        "\t\tfree(pLoadImage);\n",
        "\t\tfree_dmatrix2D(input_img_Y, nH, nW);\n",
        "\t\tfree_dmatrix2D(input_img_U, nH, nW);\n",
        "\t\tfree_dmatrix2D(input_img_V, nH, nW);\n",
        "\n",
        "\t\tcout << \"4\";\n",
        "\t}\n",
        "\n",
        "\tvoid read_image(const string filename, byte*& pLoadImage, double**& img_Y, double**& img_U, double**& img_V, int& nH, int& nW) {\n",
        "\n",
        "\t\tLoadBmp(filename.c_str(), &pLoadImage, nH, nW);///이미지파일 읽기\n",
        "\n",
        "\t\timg_Y = dmatrix2D(nH, nW);\n",
        "\t\timg_U = dmatrix2D(nH, nW);\n",
        "\t\timg_V = dmatrix2D(nH, nW);\n",
        "\n",
        "\t\tconvert1Dto2D(pLoadImage, img_Y, img_U, img_V, nH, nW);\n",
        "\n",
        "\t\t// 입력 영상을 tensor로 변환 후 첫번째 element에 저장\n",
        "\t\tdouble*** inImage3D = dmatrix3D(nH, nW, 1);\n",
        "\t\tconvert2Dto3D(img_Y, inImage3D, nH, nW);\n",
        "\n",
        "\t\tTensor3D* temp = new Tensor3D(nH, nW, 1);\n",
        "\t\ttemp->set_tensor(inImage3D);\n",
        "\t\ttensors.push_back(temp);\n",
        "\n",
        "\t}\n",
        "\tvoid save_image(string filename, byte*& pLoadImage, Tensor3D*& tensor_Y, double** img_U, double** img_V, int nH, int nW) {\n",
        "\t\tdouble** img_Y = dmatrix2D(nH, nW);\n",
        "\t\tconvert3Dto2D(tensor_Y->get_tensor(), img_Y, nH, nW);\n",
        "\t\tconvert2Dto1D(img_Y, img_U, img_V, pLoadImage, nH, nW);\n",
        "\t\tSaveBmp(filename.c_str(), pLoadImage, nH, nW);\n",
        "\t\tfree_dmatrix2D(img_Y, nH, nW);\n",
        "\t}\n",
        "\tvoid print_layer_info() const {\n",
        "\t\tcout << endl << \"(Layer information)_____________\" << endl;\n",
        "\t\tfor (unsigned i = 0; i < layers.size(); i++) {\n",
        "\t\t\tcout << i + 1 << \"-th layer: \";\n",
        "\t\t\tlayers.at(i)->print();\n",
        "\t\t}\n",
        "\t}\n",
        "\tvoid print_tensor_info() const {\n",
        "\t\tcout << endl << \"(Tensor information)_____________\" << endl;\n",
        "\t\tfor (unsigned i = 0; i < tensors.size(); i++) {\n",
        "\t\t\tcout << i + 1 << \"-th tensor: \";\n",
        "\t\t\ttensors.at(i)->print();\n",
        "\t\t}\n",
        "\t}\n",
        "\n",
        "\t//\tvoid train();\n",
        "};"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UnP-wRlFlYK",
        "outputId": "cd1d52d2-080f-451b-a8f8-14758eb90fcd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing CModel.h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile main.cpp\n",
        "\n",
        "#include \"Imagelib.h\"\n",
        "#include \"CModel.h\"\n",
        "#include \"CTensor.h\"\n",
        "#include <chrono>\n",
        "#include <cstdio>\n",
        "#include <cstdlib>\n",
        "#include <fstream>\n",
        "#include <iostream>\n",
        "#include <sstream>\n",
        "#ifdef _OPENMP\n",
        "#include <omp.h>\n",
        "#endif\n",
        "#include \"CModel.h\"\n",
        "using namespace std;\n",
        "\n",
        "// 정확하게 동작시 20점 (부분점수 없음)\n",
        "\n",
        "int main() {\n",
        "\tModel model;\n",
        "\tdouble start_time = omp_get_wtime();\n",
        "\t// build model\n",
        "\tmodel.add_layer(new Layer_Conv(\"Conv1\", 9, 1, 64, LOAD_INIT, \"/content/model/weights_conv1_9x9x1x64.txt\", \"/content/model/biases_conv1_64.txt\"));\n",
        "\tmodel.add_layer(new Layer_ReLU(\"Relu1\", 1, 64, 64));\n",
        "\tmodel.add_layer(new Layer_Conv(\"Conv2\", 5, 64, 32, LOAD_INIT, \"/content/model/weights_conv2_5x5x64x32.txt\", \"/content/model/biases_conv2_32.txt\"));\n",
        "\tmodel.add_layer(new Layer_ReLU(\"Relu2\", 1, 32, 32));\n",
        "\tmodel.add_layer(new Layer_Conv(\"Conv3\", 5, 32, 1, LOAD_INIT, \"/content/model/weights_conv3_5x5x32x1.txt\", \"/content/model/biases_conv3_1.txt\"));\n",
        "\n",
        "\n",
        "\tmodel.test(\"/content/baby_512x512_input.bmp\", \"/content/baby_512x512_output_srcnn.bmp\");\n",
        "\n",
        "\tmodel.print_layer_info();\n",
        "\tmodel.print_tensor_info();\n",
        "\tsystem(\"PAUSE\");\n",
        "\tdouble end_time = omp_get_wtime();\n",
        "\tstd::cout << \" took \" << (end_time - start_time) << \" seconds.\\n\";\n",
        "\treturn 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VH4DFCqFntq",
        "outputId": "772608a0-b2b8-43ac-b016-de40574f18e6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing main.cpp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 컴파일 (출력 실행 파일 이름은 main으로)\n",
        "!g++ -std=c++17 -O2 -Wall main.cpp -fopenmp -o main\n",
        "\n",
        "# 2. 실행\n",
        "!./main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYSDFcqNF0ZT",
        "outputId": "07c80674-591d-40eb-d8e2-982d8d1d3816"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In file included from \u001b[01m\u001b[KCModel.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kmain.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[KCLayer.h:\u001b[m\u001b[K In constructor ‘\u001b[01m\u001b[KLayer::Layer(std::string, int, int, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[KCLayer.h:23:16:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KLayer::name\u001b[m\u001b[K’ will be initialized after [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wreorder\u0007-Wreorder\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   23 |         string \u001b[01;35m\u001b[Kname\u001b[m\u001b[K;\n",
            "      |                \u001b[01;35m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[KCLayer.h:20:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K  ‘\u001b[01m\u001b[Kint Layer::fK\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wreorder\u0007-Wreorder\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   20 |         int \u001b[01;35m\u001b[KfK\u001b[m\u001b[K; // kernel size in K*K kernel\n",
            "      |             \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[KCLayer.h:25:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K  when initialized here [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wreorder\u0007-Wreorder\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   25 |         \u001b[01;35m\u001b[KLayer\u001b[m\u001b[K(string _name, int _fK, int _fC_in, int _fC_out) : name(_name), fK(_fK), fC_in(_fC_in), fC_out(_fC_out) {}\n",
            "      |         \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kmain.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kint main()\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kmain.cpp:34:15:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Kint system(const char*)\u001b[m\u001b[K’ declared with attribute ‘\u001b[01m\u001b[Kwarn_unused_result\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-result\u0007-Wunused-result\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   34 |         \u001b[01;35m\u001b[Ksystem(\"PAUSE\")\u001b[m\u001b[K;\n",
            "      |         \u001b[01;35m\u001b[K~~~~~~^~~~~~~~~\u001b[m\u001b[K\n",
            "Loading weights from /content/model/weights_conv1_9x9x1x64.txt...\n",
            "Loading biases from /content/model/biases_conv1_64.txt...\n",
            "Loading weights from /content/model/weights_conv2_5x5x64x32.txt...\n",
            "Loading biases from /content/model/biases_conv2_32.txt...\n",
            "Loading weights from /content/model/weights_conv3_5x5x32x1.txt...\n",
            "Loading biases from /content/model/biases_conv3_1.txt...\n",
            "Reading (/content/baby_512x512_input.bmp) is complete...\n",
            "Conv1 is finished\n",
            "Relu1 is finished\n",
            "Conv2 is finished\n",
            "Relu2 is finished\n",
            "Conv3 is finished\n",
            "Super-resolution is complete...\n",
            "2Tensor size: 512 x 512 x 1\n",
            "Saving (/content/baby_512x512_output_srcnn.bmp) is complete...\n",
            "34\n",
            "(Layer information)_____________\n",
            "1-th layer: Layer: Conv1 (Conv) Kernel=9 Cin=1 Cout=64\n",
            "2-th layer: Layer: Relu1 (ReLU) Kernel=1 Cin=64 Cout=64\n",
            "3-th layer: Layer: Conv2 (Conv) Kernel=5 Cin=64 Cout=32\n",
            "4-th layer: Layer: Relu2 (ReLU) Kernel=1 Cin=32 Cout=32\n",
            "5-th layer: Layer: Conv3 (Conv) Kernel=5 Cin=32 Cout=1\n",
            "\n",
            "(Tensor information)_____________\n",
            "1-th tensor: Tensor size: 512 x 512 x 1\n",
            "2-th tensor: Tensor size: 512 x 512 x 64\n",
            "3-th tensor: Tensor size: 512 x 512 x 64\n",
            "4-th tensor: Tensor size: 512 x 512 x 32\n",
            "5-th tensor: Tensor size: 512 x 512 x 32\n",
            "6-th tensor: Tensor size: 512 x 512 x 1\n",
            "7-th tensor: Tensor size: 512 x 512 x 1\n",
            "sh: 1: PAUSE: not found\n",
            " took 45.5175 seconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 병렬처리 이후"
      ],
      "metadata": {
        "id": "VxKvpftod-Bk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile Imagelib.h\n",
        "#pragma once\n",
        "#include <cstdint>\n",
        "#include <cstdio>\n",
        "#include <cstdlib>\n",
        "#include <cstring>\n",
        "#include <cassert>\n",
        "#include <iostream>\n",
        "#include <algorithm>\n",
        "#include <fstream>\n",
        "#include <string>\n",
        "#include <vector>\n",
        "#include <iomanip>\n",
        "using byte = unsigned char;\n",
        "#define LOG_OUT(_x_)\n",
        "#define LOG_OUT_W(_x_)\n",
        "#define LOG_OUT_A(_x_)\n",
        "#pragma pack(push, 1)\n",
        "typedef struct {\n",
        "    unsigned short bfType;\n",
        "    unsigned int   bfSize;\n",
        "    unsigned short bfReserved1;\n",
        "    unsigned short bfReserved2;\n",
        "    unsigned int   bfOffBits;\n",
        "} BITMAPFILEHEADER;\n",
        "\n",
        "typedef struct {\n",
        "    unsigned int   biSize;\n",
        "    int            biWidth;\n",
        "    int            biHeight;\n",
        "    unsigned short biPlanes;\n",
        "    unsigned short biBitCount;\n",
        "    unsigned int   biCompression;\n",
        "    unsigned int   biSizeImage;\n",
        "    int            biXPelsPerMeter;\n",
        "    int            biYPelsPerMeter;\n",
        "    unsigned int   biClrUsed;\n",
        "    unsigned int   biClrImportant;\n",
        "} BITMAPINFOHEADER;\n",
        "#pragma pack(pop)\n",
        "static inline uint32_t row_stride_24(int w) {\n",
        "    return (uint32_t)(((w * 3) + 3) & ~3u);\n",
        "}\n",
        "// ---- 선언 ----\n",
        "bool LoadBmp(const char* filename, byte** pImage, int& height, int& width);\n",
        "bool SaveBmp(const char* filename, byte* pImage, int height, int width);\n",
        "bool convert1Dto2D(byte* src, double** dst_Y, double** dst_U, double** dst_V, int height, int width);\n",
        "bool convert2Dto1D(double** src_Y, double** src_U, double** src_V, byte* dst, int height, int width);\n",
        "void convert2Dto3D(double **src2D, double ***dst3D, int height, int width);\n",
        "void convert3Dto2D(double ***src3D, double **dst2D, int height, int width);\n",
        "double *dmatrix1D(int nH);\n",
        "double **dmatrix2D(int nH, int nW);\n",
        "double ***dmatrix3D(int nH, int nW, int nC);\n",
        "double ****dmatrix4D(int nH, int nW, int nC, int nNum);\n",
        "void free_dmatrix1D(double *Image, int nH);\n",
        "void free_dmatrix2D(double **Image, int nH, int nW);\n",
        "void free_dmatrix3D(double ***Image, int nH, int nW, int nC);\n",
        "void free_dmatrix4D(double ****Image, int nH, int nW, int nC, int nNum);\n",
        "double clip(double x, double minVal, double maxVal);\n",
        "double** simpleUpsampling2x(double **Image, int nH, int nW);\n",
        "\n",
        "\n",
        "// ---- 정의 ----\n",
        "bool LoadBmp(const char* filename, byte** pImage, int& height, int& width) {\n",
        "    *pImage = nullptr;\n",
        "    std::FILE* fp = std::fopen(filename, \"rb\");\n",
        "    if (!fp) { LOG_OUT_A(\"fopen() error\"); return false; }\n",
        "    BITMAPFILEHEADER bmf{};\n",
        "    BITMAPINFOHEADER bmi{};\n",
        "    if (std::fread(&bmf, sizeof(bmf), 1, fp) != 1) { std::fclose(fp); return false; }\n",
        "    if (bmf.bfType != 0x4D42) { std::fclose(fp); LOG_OUT_A(\"not .bmp file\"); return false; }\n",
        "    if (std::fread(&bmi, sizeof(bmi), 1, fp) != 1) { std::fclose(fp); return false; }\n",
        "    if (bmi.biBitCount != 24 || bmi.biCompression != 0 /*BI_RGB*/) {\n",
        "        std::fclose(fp); LOG_OUT_A(\"only 24-bit BI_RGB supported\"); return false;\n",
        "    }\n",
        "    width  = bmi.biWidth;\n",
        "    height = (bmi.biHeight >= 0) ? bmi.biHeight : -bmi.biHeight;\n",
        "    const bool bottom_up = (bmi.biHeight > 0);\n",
        "    const uint32_t stride = row_stride_24(width);\n",
        "    const uint32_t data_bytes = stride * (uint32_t)height;\n",
        "    // 픽셀 데이터 위치로 이동\n",
        "    if (bmf.bfOffBits > sizeof(bmf) + sizeof(bmi)) {\n",
        "        std::fseek(fp, (long)bmf.bfOffBits, SEEK_SET);\n",
        "    }\n",
        "    // 원본(패딩 포함) 읽기\n",
        "    std::vector<unsigned char> buf(data_bytes);\n",
        "    if (std::fread(buf.data(), 1, data_bytes, fp) != data_bytes) { std::fclose(fp); return false; }\n",
        "    std::fclose(fp);\n",
        "    // 호출자용 포맷: 패딩 없음, top→bottom, BGR 연속 메모리\n",
        "    *pImage = (byte*)std::malloc((size_t)width * height * 3);\n",
        "    if (!*pImage) return false;\n",
        "    for (int y = 0; y < height; ++y) {\n",
        "        int src_y = bottom_up ? (height - 1 - y) : y;\n",
        "        const unsigned char* src = buf.data() + (size_t)src_y * stride;\n",
        "        byte* dst = *pImage + (size_t)y * width * 3;\n",
        "        std::memcpy(dst, src, (size_t)width * 3);\n",
        "    }\n",
        "    return true;\n",
        "}\n",
        "bool SaveBmp(const char* filename, byte* pImage, int height, int width) {\n",
        "    // pImage: top→bottom, 패딩 없음, BGR 연속\n",
        "    const uint32_t stride = row_stride_24(width);\n",
        "    const uint32_t data_bytes = stride * (uint32_t)height;\n",
        "    BITMAPFILEHEADER bmf{};\n",
        "    BITMAPINFOHEADER bmi{};\n",
        "    bmi.biSize = sizeof(BITMAPINFOHEADER);\n",
        "    bmi.biWidth = width;\n",
        "    bmi.biHeight = height;        // bottom-up 저장(양수)\n",
        "    bmi.biPlanes = 1;\n",
        "    bmi.biBitCount = 24;\n",
        "    bmi.biCompression = 0;        // BI_RGB\n",
        "    bmi.biSizeImage = data_bytes;\n",
        "    bmf.bfType = 0x4D42; // 'BM'\n",
        "    bmf.bfOffBits = sizeof(BITMAPFILEHEADER) + sizeof(BITMAPINFOHEADER);\n",
        "    bmf.bfSize = bmf.bfOffBits + data_bytes;\n",
        "    std::FILE* fp = std::fopen(filename, \"wb\");\n",
        "    if (!fp) { LOG_OUT_A(\"fopen() error\"); return false; }\n",
        "    std::fwrite(&bmf, 1, sizeof(bmf), fp);\n",
        "    std::fwrite(&bmi, 1, sizeof(bmi), fp);\n",
        "    std::vector<unsigned char> row(stride, 0);\n",
        "    for (int y = height - 1; y >= 0; --y) {\n",
        "        const byte* src = pImage + (size_t)y * width * 3;\n",
        "        std::memcpy(row.data(), src, (size_t)width * 3);\n",
        "        std::fwrite(row.data(), 1, stride, fp);\n",
        "    }\n",
        "    std::fclose(fp);\n",
        "    return true;\n",
        "}\n",
        "bool convert1Dto2D(byte* src, double** dst_Y, double** dst_U, double** dst_V, int height, int width) {\n",
        "    int iR, iG, iB;\n",
        "    for (int y = 0; y < height; y++) {\n",
        "        for (int x = 0; x < width; x++) {\n",
        "            iB = src[3 * width * y + 3 * x + 0];\n",
        "            iG = src[3 * width * y + 3 * x + 1];\n",
        "            iR = src[3 * width * y + 3 * x + 2];\n",
        "            dst_Y[y][x] = iR * 0.299 + iG * 0.587 + iB * 0.114;\n",
        "            dst_U[y][x] = (iB - dst_Y[y][x]) * 0.565;\n",
        "            dst_V[y][x] = (iR - dst_Y[y][x]) * 0.713;\n",
        "            dst_Y[y][x] = dst_Y[y][x] / 255.0; // [0,255] → [0,1]\n",
        "        }\n",
        "    }\n",
        "    return true;\n",
        "}\n",
        "bool convert2Dto1D(double** src_Y, double** src_U, double** src_V, byte* dst, int height, int width) {\n",
        "    int iCount = 0;\n",
        "    int iR, iG, iB;\n",
        "    for (int y = 0; y < height; y++) {\n",
        "        for (int x = 0; x < width; x++) {\n",
        "            double Y = src_Y[y][x] * 255.0;\n",
        "            iR = (int)clip(Y + 1.403 * src_V[y][x], 0, 255);\n",
        "            iG = (int)clip(Y - 0.344 * src_U[y][x] - 0.714 * src_V[y][x], 0, 255);\n",
        "            iB = (int)clip(Y + 1.770 * src_U[y][x], 0, 255);\n",
        "            dst[iCount + 0] = (byte)iB;\n",
        "            dst[iCount + 1] = (byte)iG;\n",
        "            dst[iCount + 2] = (byte)iR;\n",
        "            iCount += 3;\n",
        "        }\n",
        "    }\n",
        "    return true;\n",
        "}\n",
        "double clip(double x, double minVal, double maxVal) {\n",
        "    if (x < minVal) x = minVal;\n",
        "    if (x > maxVal) x = maxVal;\n",
        "    return x;\n",
        "}\n",
        "double** simpleUpsampling2x(double **Image, int nH, int nW) {\n",
        "    double** outImg = dmatrix2D(nH * 2, nW * 2);\n",
        "    for (int y = 0; y < nH; y++) {\n",
        "        for (int x = 0; x < nW; x++) {\n",
        "            outImg[2 * y + 0][2 * x + 0] = Image[y][x];\n",
        "            outImg[2 * y + 0][2 * x + 1] = Image[y][x];\n",
        "            outImg[2 * y + 1][2 * x + 0] = Image[y][x];\n",
        "            outImg[2 * y + 1][2 * x + 1] = Image[y][x];\n",
        "        }\n",
        "    }\n",
        "    return outImg;\n",
        "}\n",
        "double *dmatrix1D(int nH) {\n",
        "    return new double[nH]();\n",
        "}\n",
        "double **dmatrix2D(int nH, int nW) {\n",
        "    double **Temp = new double*[nH];\n",
        "    for (int y = 0; y < nH; y++) Temp[y] = new double[nW]();\n",
        "    return Temp;\n",
        "}\n",
        "double ***dmatrix3D(int nH, int nW, int nC) {\n",
        "    double ***Temp = new double**[nH];\n",
        "    for (int y = 0; y < nH; y++) {\n",
        "        Temp[y] = new double*[nW];\n",
        "        for (int x = 0; x < nW; x++) Temp[y][x] = new double[nC]();\n",
        "    }\n",
        "    return Temp;\n",
        "}\n",
        "double ****dmatrix4D(int nH, int nW, int nC, int nNum) {\n",
        "    double ****Temp = new double***[nH];\n",
        "    for (int y = 0; y < nH; y++) {\n",
        "        Temp[y] = new double**[nW];\n",
        "        for (int x = 0; x < nW; x++) {\n",
        "            Temp[y][x] = new double*[nC];\n",
        "            for (int c = 0; c < nC; c++) Temp[y][x][c] = new double[nNum]();\n",
        "        }\n",
        "    }\n",
        "    return Temp;\n",
        "}\n",
        "void free_dmatrix1D(double *Image, int) { delete[] Image; }\n",
        "void free_dmatrix2D(double **Image, int nH, int) {\n",
        "    for (int y = 0; y < nH; y++) delete[] Image[y];\n",
        "    delete[] Image;\n",
        "}\n",
        "void free_dmatrix3D(double ***Image, int nH, int nW, int) {\n",
        "    for (int y = 0; y < nH; y++) {\n",
        "        for (int x = 0; x < nW; x++) delete[] Image[y][x];\n",
        "        delete[] Image[y];\n",
        "    }\n",
        "    delete[] Image;\n",
        "}\n",
        "void free_dmatrix4D(double ****Image, int nH, int nW, int nC, int) {\n",
        "    for (int y = 0; y < nH; y++) {\n",
        "        for (int x = 0; x < nW; x++) {\n",
        "            for (int c = 0; c < nC; c++) delete[] Image[y][x][c];\n",
        "            delete[] Image[y][x];\n",
        "        }\n",
        "        delete[] Image[y];\n",
        "    }\n",
        "    delete[] Image;\n",
        "}\n",
        "void convert2Dto3D(double **src2D, double ***dst3D, int height, int width) {\n",
        "    for (int y = 0; y < height; y++)\n",
        "        for (int x = 0; x < width; x++)\n",
        "            dst3D[y][x][0] = src2D[y][x];\n",
        "}\n",
        "void convert3Dto2D(double ***src3D, double **dst2D, int height, int width) {\n",
        "    for (int y = 0; y < height; y++)\n",
        "        for (int x = 0; x < width; x++)\n",
        "            dst2D[y][x] = src3D[y][x][0];\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTp-oyAlg3IC",
        "outputId": "8b2d0056-22fe-4d12-9b92-57bf7bb323e4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting Imagelib.h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile CTensor.h\n",
        "\n",
        "#pragma once\n",
        "#include \"Imagelib.h\"\n",
        "#include <iostream>\n",
        "#include <fstream>\n",
        "#include <stdexcept>\n",
        "#include <string>\n",
        "using std::cout;\n",
        "using std::endl;\n",
        "using std::string;\n",
        "\n",
        "// Tensor3D는 크기가 (nH x nW x nC)인 3차원 tensor를 관리함\n",
        "\n",
        "class Tensor3D {\n",
        "private:\n",
        "\tdouble*** tensor;\n",
        "\tint nH; // height\n",
        "\tint nW; // width\n",
        "\tint nC; // channel\n",
        "public:\n",
        "\tTensor3D(int _nH, int _nW, int _nC) : nH(_nH), nW(_nW), nC(_nC) {\n",
        "\t\t// (구현할 것)//////////////////////////////////////////////////////////////////////\n",
        "\t\t// 동작:\n",
        "\t\t//\n",
        "\t\t// 사용함수: dmatrix3D(): 3차원 행렬을 동적 할당해서 pointer를 반환하는 함수\n",
        "\t\ttensor = dmatrix3D(nH, nW, nC);\n",
        "\t}\n",
        "\t~Tensor3D() {\n",
        "\t\t// (구현할 것)//////////////////////////////////////////////////////////////////////\n",
        "\t\t// 동작: 3차원 동적 배열인 tensor를 할당 해제\n",
        "\t\t// 사용함수: free_dmatrix3D(): 3차원 동적 할당된 행렬을 할당 해제하는 함수\n",
        "\t\tfree_dmatrix3D(tensor, nH, nW, nC);\n",
        "\t}\n",
        "\tvoid set_elem(int _h, int _w, int _c, double _val) { tensor[_h][_w][_c] = _val; }\n",
        "\tdouble get_elem(int _h, int _w, int _c)\tconst {\n",
        "\t\t// (구현할 것)//////////////////////////////////////////////////////////////////////\n",
        "\t\t// 동작: 행=_h, 열= _w, 채널= _c 위치 element를 반환할 것\n",
        "\t\treturn tensor[_h][_w][_c];\n",
        "\t}\n",
        "\n",
        "\tvoid get_info(int& _nH, int& _nW, int& _nC) const {\n",
        "\t\t// (구현할 것)//////////////////////////////////////////////////////////////////////\n",
        "\t\t// 동작: 행렬의 차원(nH, nW, nC)을 pass by reference로 반환\n",
        "\t\t_nH = nH;\n",
        "\t\t_nW = nW;\n",
        "\t\t_nC = nC;\n",
        "\t}\n",
        "\n",
        "\tvoid set_tensor(double*** _tensor) { tensor = _tensor; }\n",
        "\tdouble*** get_tensor() const { return tensor; }\n",
        "\n",
        "\tvoid print() const {\n",
        "\t\t// (구현할 것)//////////////////////////////////////////////////////////////////////\n",
        "\t\t// 동작: 행렬의 크기 (nH*nW*nC)를 화면에 출력\n",
        "\t\tprintf(\"Tensor size: %d x %d x %d\\n\", nH, nW, nC);\n",
        "\t}\n",
        "};"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCxKFvocg6no",
        "outputId": "9c5171e5-6e5f-46ec-9fc6-7abfc95a7661"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting CTensor.h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile CLayer.h\n",
        "#pragma once\n",
        "#include <iostream>\n",
        "#include <fstream>\n",
        "#include <stdexcept>\n",
        "#include <string>\n",
        "#include <omp.h>\n",
        "#include \"Imagelib.h\"\n",
        "#include \"CTensor.h\"\n",
        "#define MEAN_INIT 0\n",
        "#define LOAD_INIT 1\n",
        "using std::cout;\n",
        "using std::endl;\n",
        "using std::string;\n",
        "\n",
        "class Layer {\n",
        "protected:\n",
        "\tint fK; // kernel size in K*K kernel\n",
        "\tint fC_in; // number of channels\n",
        "\tint fC_out; //number of filters\n",
        "\tstring name;\n",
        "public:\n",
        "\tLayer(string _name, int _fK, int _fC_in, int _fC_out) : name(_name), fK(_fK), fC_in(_fC_in), fC_out(_fC_out) {}\n",
        "\tvirtual ~Layer() {};\n",
        "\tvirtual Tensor3D* forward(const Tensor3D* input) = 0;\n",
        "\tvirtual void print() const = 0;\n",
        "\tvirtual void get_info(string& _name, int& _fK, int& _fC_in, int& _fC_out) const = 0;\n",
        "};\n",
        "\n",
        "class Layer_ReLU : public Layer {\n",
        "public:\n",
        "\tLayer_ReLU(string _name, int _fK, int _fC_in, int _fC_out)\n",
        "\t\t: Layer(_name, _fK, _fC_in, _fC_out) {}\n",
        "\t~Layer_ReLU() {}\n",
        "\n",
        "\tTensor3D* forward(const Tensor3D* input) override {\n",
        "\t\tint H, W, C;\n",
        "\t\tinput->get_info(H, W, C);\n",
        "\n",
        "\t\tTensor3D* output = new Tensor3D(H, W, C);\n",
        "\n",
        "\t\t#pragma omp parallel for collapse(3)\n",
        "\t\tfor (int h = 0; h < H; h++) {\n",
        "\t\t\tfor (int w = 0; w < W; w++) {\n",
        "\t\t\t\tfor (int c = 0; c < C; c++) {\n",
        "\t\t\t\t\tdouble val = input->get_elem(h, w, c);\n",
        "\t\t\t\t\toutput->set_elem(h, w, c, (val > 0) ? val : 0.0);\n",
        "\t\t\t\t}\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\n",
        "\t\tcout << name << \" is finished\" << endl;\n",
        "\t\treturn output;\n",
        "\t};\n",
        "\n",
        "\tvoid get_info(string& _name, int& _fK, int& _fC_in, int& _fC_out) const override {\n",
        "\t\t_name = name;\n",
        "\t\t_fK = fK;\n",
        "\t\t_fC_in = fC_in;\n",
        "\t\t_fC_out = fC_out;\n",
        "\t}\n",
        "\n",
        "\tvoid print() const override {\n",
        "\t\tcout << \"Layer: \" << name << \" (ReLU) \"\n",
        "\t\t\t<< \"Kernel=\" << fK\n",
        "\t\t\t<< \" Cin=\" << fC_in\n",
        "\t\t\t<< \" Cout=\" << fC_out << endl;\n",
        "\t}\n",
        "};\n",
        "\n",
        "class Layer_Conv : public Layer {\n",
        "private:\n",
        "\tstring filename_weight;\n",
        "\tstring filename_bias;\n",
        "\tdouble**** weight_tensor;\n",
        "\tdouble*  bias_tensor;\n",
        "public:\n",
        "\tLayer_Conv(string _name, int _fK, int _fC_in, int _fC_out, int init_type, string _filename_weight = \"\", string _filename_bias = \"\")\n",
        "\t:Layer(_name, _fK, _fC_in, _fC_out), filename_weight(_filename_weight), filename_bias(_filename_bias)\n",
        "\t{\n",
        "\t\tweight_tensor = dmatrix4D(fK, fK, fC_in, fC_out);\n",
        "\t\tbias_tensor = dmatrix1D(fC_out);\n",
        "\t\tinit(init_type);\n",
        "\t}\n",
        "\n",
        "\tvoid init(int init_type) {\n",
        "\t\tif (init_type == MEAN_INIT) {\n",
        "\t\t\tdouble val = 1.0 / (fK * fK * fC_in);\n",
        "\t\t\tfor (int y = 0; y < fK; y++)\n",
        "\t\t\t\tfor (int x = 0; x < fK; x++)\n",
        "\t\t\t\t\tfor (int c = 0; c < fC_in; c++)\n",
        "\t\t\t\t\t\tfor (int n = 0; n < fC_out; n++)\n",
        "\t\t\t\t\t\t\tweight_tensor[y][x][c][n] = val;\n",
        "\t\t\tfor (int n = 0; n < fC_out; n++) bias_tensor[n] = 0.0;\n",
        "\t\t}\n",
        "\t\telse if (init_type == LOAD_INIT) {\n",
        "\t\t\tstd::ifstream weight_file(filename_weight);\n",
        "\t\t\tif (!weight_file.is_open()) { std::cerr << \"Error: Could not open weight file: \" << filename_weight << std::endl; exit(EXIT_FAILURE); }\n",
        "\t\t\tfor (int y = 0; y < fK; y++)\n",
        "\t\t\t\tfor (int x = 0; x < fK; x++)\n",
        "\t\t\t\t\tfor (int c = 0; c < fC_in; c++)\n",
        "\t\t\t\t\t\tfor (int n = 0; n < fC_out; n++)\n",
        "\t\t\t\t\t\t\tweight_file >> weight_tensor[y][x][c][n];\n",
        "\t\t\tweight_file.close();\n",
        "\n",
        "\t\t\tstd::ifstream bias_file(filename_bias);\n",
        "\t\t\tif (!bias_file.is_open()) { std::cerr << \"Error: Could not open bias file: \" << filename_bias << std::endl; exit(EXIT_FAILURE); }\n",
        "\t\t\tfor (int n = 0; n < fC_out; n++) bias_file >> bias_tensor[n];\n",
        "\t\t\tbias_file.close();\n",
        "\t\t}\n",
        "\t}\n",
        "\n",
        "\t~Layer_Conv() override {\n",
        "\t\tfree_dmatrix4D(weight_tensor, fK, fK, fC_in, fC_out);\n",
        "\t\tfree_dmatrix1D(bias_tensor, fC_out);\n",
        "\t}\n",
        "\n",
        "\tTensor3D* forward(const Tensor3D* input) override {\n",
        "\t\tint H, W, C;\n",
        "\t\tinput->get_info(H, W, C);\n",
        "\t\tassert(C == fC_in);\n",
        "\n",
        "\t\tint pad = fK / 2;\n",
        "\t\tint outH = H, outW = W;\n",
        "\t\tTensor3D* output = new Tensor3D(outH, outW, fC_out);\n",
        "\n",
        "\t\t#pragma omp parallel for collapse(3) schedule(dynamic)\n",
        "\t\tfor (int oh = 0; oh < outH; oh++) {\n",
        "\t\t\tfor (int ow = 0; ow < outW; ow++) {\n",
        "\t\t\t\tfor (int f = 0; f < fC_out; f++) {\n",
        "\t\t\t\t\tdouble sum = 0.0;\n",
        "\t\t\t\t\tfor (int kh = 0; kh < fK; kh++) {\n",
        "\t\t\t\t\t\tfor (int kw = 0; kw < fK; kw++) {\n",
        "\t\t\t\t\t\t\tfor (int c = 0; c < fC_in; c++) {\n",
        "\t\t\t\t\t\t\t\tint ih = oh + kh - pad;\n",
        "\t\t\t\t\t\t\t\tint iw = ow + kw - pad;\n",
        "\t\t\t\t\t\t\t\tif (ih >= 0 && ih < H && iw >= 0 && iw < W)\n",
        "\t\t\t\t\t\t\t\t\tsum += input->get_elem(ih, iw, c) * weight_tensor[kh][kw][c][f];\n",
        "\t\t\t\t\t\t\t}\n",
        "\t\t\t\t\t\t}\n",
        "\t\t\t\t\t}\n",
        "\t\t\t\t\tsum += bias_tensor[f];\n",
        "\t\t\t\t\toutput->set_elem(oh, ow, f, sum);\n",
        "\t\t\t\t}\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\n",
        "\t\tcout << name << \" is finished\" << endl;\n",
        "\t\treturn output;\n",
        "\t}\n",
        "\n",
        "\tvoid get_info(string& _name, int& _fK, int& _fC_in, int& _fC_out) const override {\n",
        "\t\t_name = name;\n",
        "\t\t_fK = fK;\n",
        "\t\t_fC_in = fC_in;\n",
        "\t\t_fC_out = fC_out;\n",
        "\t}\n",
        "\n",
        "\tvoid print() const override {\n",
        "\t\tcout << \"Layer: \" << name << \" (Conv) \"\n",
        "\t\t\t<< \"Kernel=\" << fK\n",
        "\t\t\t<< \" Cin=\" << fC_in\n",
        "\t\t\t<< \" Cout=\" << fC_out << endl;\n",
        "\t}\n",
        "};\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmFXfckAOStW",
        "outputId": "89dcf4a6-793e-4ee1-fd15-51dab86d3ea0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting CLayer.h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile CModel.h\n",
        "#pragma once\n",
        "#include <vector>\n",
        "#include <string>\n",
        "#include <iostream>\n",
        "#include <iomanip>\n",
        "#include \"CLayer.h\"\n",
        "using std::vector;\n",
        "using std::string;\n",
        "using std::cout;\n",
        "\n",
        "using std::endl;\n",
        "using std::setw;\n",
        "\n",
        "// Model은 layer와 tensor들을 모두 통합 관리하여 효과적으로 CNN이 수행될 수 있도록 함\n",
        "\n",
        "class Model {\n",
        "private:\n",
        "\tvector<Layer*> layers; //layer들을 순차적으로 저장\n",
        "\tvector<Tensor3D*> tensors;// tensor들을 순차적으로 저장 ( 0번째 tensor는 0번째 layer의 입력, 마찬가지로 1번째 tensor는 1번째 layer의 입력이자 0번째 layer의 출력임)\n",
        "public:\n",
        "\tModel() {}\n",
        "\tvoid add_layer(Layer* layer) {\n",
        "\t\t// (구현할 것) //////////////////////////////////////////////////\n",
        "\t\t// 동작: layer 객체를 layers vector의 마지막 element로 저장\n",
        "\t\tlayers.push_back(layer);\n",
        "\t}\n",
        "\t~Model() {\n",
        "\t\t// (구현할 것)//////////////////////////////////////////////////\n",
        "\t\t// 동작: layers와 tensors의 모든 element를 동적할당 해제해 줄 것\n",
        "\t\tfor (auto& l : layers) {\n",
        "\t\t\tdelete l;\n",
        "\t\t}\n",
        "\t\tlayers.clear();\n",
        "\n",
        "\t\tfor (auto& t : tensors) {\n",
        "\t\t\tdelete t;\n",
        "\t\t}\n",
        "\t\ttensors.clear();\n",
        "\t}\n",
        "\tvoid test(string filename_input, string filename_output) {\n",
        "\t\t// (구현할 것)//////////////////////////////////////////////////\n",
        "\t\t// 동작1: filename_input으로부터 이미지를 읽어와서, tensor로 변환한 다음 CNN을 수행한다음 그 결과물을 filename_output에 저장\n",
        "\t\t// 동작2: 주석 (1), (2), (3), (4) 중 (2)번만 구현하면 됨\n",
        "\n",
        "\t\tint nH, nW;\n",
        "\t\tdouble** input_img_Y, **input_img_U, **input_img_V;\n",
        "\t\tbyte* pLoadImage;\n",
        "\n",
        "\t\t// (1) 영상을 읽어서 2차원 배열로 저장 (input_img_Y, U, V는 read_image에서 동적 할당됨)\n",
        "\t\tread_image(filename_input, pLoadImage, input_img_Y, input_img_U, input_img_V, nH, nW);\n",
        "\t\tcout << \"Reading (\" << filename_input << \") is complete...\" << endl;\n",
        "\n",
        "\n",
        "\t\t// (2) 이부분만 구현할 것//////////////////////////////////////////////////\n",
        "\t\t// 동작1: 현재 tensors의 0번째 element에 영상(CNN의 입력)이 이미 저장되어 있음\n",
        "\t\t// 동작2: tensors vector의 i번째 tensor를 layers vector에 있는 i번째 layer의 forward함수로 입력받고, 그 결과를 tensors vector의 i+1번째 tensor로 저장함\n",
        "\t\t// 동작3: 결과적으로 tensors의 가장 마지막 tensor는 CNN의 출력값이 됨 (이 출력값은 (3)에서 1차원 배열로 변환되어 이미지 파일에 저장됨\n",
        "\t\tfor (size_t i = 0; i < layers.size(); i++) {\n",
        "\t\t\tTensor3D* input_tensor = tensors.at(i);            // i번째 tensor를 입력으로\n",
        "\t\t\tTensor3D* output_tensor = layers.at(i)->forward(input_tensor); // layer forward\n",
        "\t\t\ttensors.push_back(output_tensor);                  // i+1번째 tensor로 추가\n",
        "\n",
        "\t\t}\n",
        "\t\tTensor3D* input_tensor = tensors.at(0);\n",
        "\t\tTensor3D* residual_tensor = tensors.at(tensors.size() - 1);\n",
        "\n",
        "\t\tint H, W, C;\n",
        "\t\tinput_tensor->get_info(H, W, C);\n",
        "\n",
        "\t\t// 최종 결과를 저장할 새로운 텐서를 생성\n",
        "\t\tTensor3D* final_image_tensor = new Tensor3D(H, W, C);\n",
        "\n",
        "\t\tfor (int h = 0; h < H; h++) {\n",
        "\t\t\tfor (int w = 0; w < W; w++) {\n",
        "\t\t\t\tdouble input_val = input_tensor->get_elem(h, w, 0);\n",
        "\t\t\t\tdouble residual_val = residual_tensor->get_elem(h, w, 0);\n",
        "\t\t\t\t// 원본 + 차이 값 = 최종 결과\n",
        "\t\t\t\tfinal_image_tensor->set_elem(h, w, 0, input_val + residual_val);\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t\t// 완성된 최종 이미지를 텐서 목록의 맨 뒤에 추가\n",
        "\t\ttensors.push_back(final_image_tensor);\n",
        "\n",
        "\t\tcout << \"Super-resolution is complete...\" << endl;\n",
        "\n",
        "\t\tcout << \"2\";\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\t\t// (3) CNN의 출력(마지막 tensor)을 2차원 배열로 변환 후 U, V 채널과 함께 이미지로 저장\n",
        "\t\tTensor3D* output_tensor_Y = tensors.at(tensors.size() - 1);\n",
        "\t\toutput_tensor_Y->print();\n",
        "\t\tsave_image(filename_output, pLoadImage, output_tensor_Y, input_img_U, input_img_V, nH, nW);\n",
        "\t\tcout << \"Saving (\" << filename_output << \") is complete...\" << endl;\n",
        "\n",
        "\t\tcout << \"3\";\n",
        "\n",
        "\t\t// (4) 할당 해제\n",
        "\t\tfree(pLoadImage);\n",
        "\t\tfree_dmatrix2D(input_img_Y, nH, nW);\n",
        "\t\tfree_dmatrix2D(input_img_U, nH, nW);\n",
        "\t\tfree_dmatrix2D(input_img_V, nH, nW);\n",
        "\n",
        "\t\tcout << \"4\";\n",
        "\t}\n",
        "\n",
        "\tvoid read_image(const string filename, byte*& pLoadImage, double**& img_Y, double**& img_U, double**& img_V, int& nH, int& nW) {\n",
        "\n",
        "\t\tLoadBmp(filename.c_str(), &pLoadImage, nH, nW);///이미지파일 읽기\n",
        "\n",
        "\t\timg_Y = dmatrix2D(nH, nW);\n",
        "\t\timg_U = dmatrix2D(nH, nW);\n",
        "\t\timg_V = dmatrix2D(nH, nW);\n",
        "\n",
        "\t\tconvert1Dto2D(pLoadImage, img_Y, img_U, img_V, nH, nW);\n",
        "\n",
        "\t\t// 입력 영상을 tensor로 변환 후 첫번째 element에 저장\n",
        "\t\tdouble*** inImage3D = dmatrix3D(nH, nW, 1);\n",
        "\t\tconvert2Dto3D(img_Y, inImage3D, nH, nW);\n",
        "\n",
        "\t\tTensor3D* temp = new Tensor3D(nH, nW, 1);\n",
        "\t\ttemp->set_tensor(inImage3D);\n",
        "\t\ttensors.push_back(temp);\n",
        "\n",
        "\t}\n",
        "\tvoid save_image(string filename, byte*& pLoadImage, Tensor3D*& tensor_Y, double** img_U, double** img_V, int nH, int nW) {\n",
        "\t\tdouble** img_Y = dmatrix2D(nH, nW);\n",
        "\t\tconvert3Dto2D(tensor_Y->get_tensor(), img_Y, nH, nW);\n",
        "\t\tconvert2Dto1D(img_Y, img_U, img_V, pLoadImage, nH, nW);\n",
        "\t\tSaveBmp(filename.c_str(), pLoadImage, nH, nW);\n",
        "\t\tfree_dmatrix2D(img_Y, nH, nW);\n",
        "\t}\n",
        "\tvoid print_layer_info() const {\n",
        "\t\tcout << endl << \"(Layer information)_____________\" << endl;\n",
        "\t\tfor (unsigned i = 0; i < layers.size(); i++) {\n",
        "\t\t\tcout << i + 1 << \"-th layer: \";\n",
        "\t\t\tlayers.at(i)->print();\n",
        "\t\t}\n",
        "\t}\n",
        "\tvoid print_tensor_info() const {\n",
        "\t\tcout << endl << \"(Tensor information)_____________\" << endl;\n",
        "\t\tfor (unsigned i = 0; i < tensors.size(); i++) {\n",
        "\t\t\tcout << i + 1 << \"-th tensor: \";\n",
        "\t\t\ttensors.at(i)->print();\n",
        "\t\t}\n",
        "\t}\n",
        "\n",
        "\t//\tvoid train();\n",
        "};"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGTMI75ihASB",
        "outputId": "b9648036-ef8e-41c1-e134-80b268ef8ebe"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting CModel.h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile main_p.cpp\n",
        "\n",
        "#include \"Imagelib.h\"\n",
        "#include \"CModel.h\"\n",
        "#include \"CTensor.h\"\n",
        "#include <chrono>\n",
        "#include <cstdio>\n",
        "#include <cstdlib>\n",
        "#include <fstream>\n",
        "#include <iostream>\n",
        "#include <sstream>\n",
        "#ifdef _OPENMP\n",
        "#include <omp.h>\n",
        "#endif\n",
        "#include \"CModel.h\"\n",
        "using namespace std;\n",
        "\n",
        "// 정확하게 동작시 20점 (부분점수 없음)\n",
        "\n",
        "int main() {\n",
        "\tModel model;\n",
        "\tdouble start_time = omp_get_wtime();\n",
        "\t// build model\n",
        "\tmodel.add_layer(new Layer_Conv(\"Conv1\", 9, 1, 64, LOAD_INIT, \"/content/model/weights_conv1_9x9x1x64.txt\", \"/content/model/biases_conv1_64.txt\"));\n",
        "\tmodel.add_layer(new Layer_ReLU(\"Relu1\", 1, 64, 64));\n",
        "\tmodel.add_layer(new Layer_Conv(\"Conv2\", 5, 64, 32, LOAD_INIT, \"/content/model/weights_conv2_5x5x64x32.txt\", \"/content/model/biases_conv2_32.txt\"));\n",
        "\tmodel.add_layer(new Layer_ReLU(\"Relu2\", 1, 32, 32));\n",
        "\tmodel.add_layer(new Layer_Conv(\"Conv3\", 5, 32, 1, LOAD_INIT, \"/content/model/weights_conv3_5x5x32x1.txt\", \"/content/model/biases_conv3_1.txt\"));\n",
        "\n",
        "\n",
        "\tmodel.test(\"/content/baby_512x512_input.bmp\", \"/content/baby_512x512_output_srcnn.bmp\");\n",
        "\n",
        "\tmodel.print_layer_info();\n",
        "\tmodel.print_tensor_info();\n",
        "\tsystem(\"PAUSE\");\n",
        "\tdouble end_time = omp_get_wtime();\n",
        "\tstd::cout << \" took \" << (end_time - start_time) << \" seconds.\\n\";\n",
        "\treturn 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ObfjUAtglIM",
        "outputId": "41161b03-e38d-41d5-81a5-a56175243d0a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing main_p.cpp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 컴파일 (출력 실행 파일 이름은 main으로)\n",
        "!g++ -std=c++17 -O2 -Wall main_p.cpp -fopenmp -o main_p\n",
        "\n",
        "# 2. 실행\n",
        "!./main_p"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mX7MWDrgnrw",
        "outputId": "36fd0bce-1221-4db0-fef0-d54ec678be69"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In file included from \u001b[01m\u001b[KCModel.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kmain_p.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[KCLayer.h:\u001b[m\u001b[K In constructor ‘\u001b[01m\u001b[KLayer::Layer(std::string, int, int, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[KCLayer.h:20:16:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KLayer::name\u001b[m\u001b[K’ will be initialized after [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wreorder\u0007-Wreorder\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   20 |         string \u001b[01;35m\u001b[Kname\u001b[m\u001b[K;\n",
            "      |                \u001b[01;35m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[KCLayer.h:17:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K  ‘\u001b[01m\u001b[Kint Layer::fK\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wreorder\u0007-Wreorder\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   17 |         int \u001b[01;35m\u001b[KfK\u001b[m\u001b[K; // kernel size in K*K kernel\n",
            "      |             \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[KCLayer.h:22:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K  when initialized here [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wreorder\u0007-Wreorder\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   22 |         \u001b[01;35m\u001b[KLayer\u001b[m\u001b[K(string _name, int _fK, int _fC_in, int _fC_out) : name(_name), fK(_fK), fC_in(_fC_in), fC_out(_fC_out) {}\n",
            "      |         \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kmain_p.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kint main()\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kmain_p.cpp:34:15:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Kint system(const char*)\u001b[m\u001b[K’ declared with attribute ‘\u001b[01m\u001b[Kwarn_unused_result\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-result\u0007-Wunused-result\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   34 |         \u001b[01;35m\u001b[Ksystem(\"PAUSE\")\u001b[m\u001b[K;\n",
            "      |         \u001b[01;35m\u001b[K~~~~~~^~~~~~~~~\u001b[m\u001b[K\n",
            "Reading (/content/baby_512x512_input.bmp) is complete...\n",
            "Conv1 is finished\n",
            "Relu1 is finished\n",
            "Conv2 is finished\n",
            "Relu2 is finished\n",
            "Conv3 is finished\n",
            "Super-resolution is complete...\n",
            "2Tensor size: 512 x 512 x 1\n",
            "Saving (/content/baby_512x512_output_srcnn.bmp) is complete...\n",
            "34\n",
            "(Layer information)_____________\n",
            "1-th layer: Layer: Conv1 (Conv) Kernel=9 Cin=1 Cout=64\n",
            "2-th layer: Layer: Relu1 (ReLU) Kernel=1 Cin=64 Cout=64\n",
            "3-th layer: Layer: Conv2 (Conv) Kernel=5 Cin=64 Cout=32\n",
            "4-th layer: Layer: Relu2 (ReLU) Kernel=1 Cin=32 Cout=32\n",
            "5-th layer: Layer: Conv3 (Conv) Kernel=5 Cin=32 Cout=1\n",
            "\n",
            "(Tensor information)_____________\n",
            "1-th tensor: Tensor size: 512 x 512 x 1\n",
            "2-th tensor: Tensor size: 512 x 512 x 64\n",
            "3-th tensor: Tensor size: 512 x 512 x 64\n",
            "4-th tensor: Tensor size: 512 x 512 x 32\n",
            "5-th tensor: Tensor size: 512 x 512 x 32\n",
            "6-th tensor: Tensor size: 512 x 512 x 1\n",
            "7-th tensor: Tensor size: 512 x 512 x 1\n",
            "sh: 1: PAUSE: not found\n",
            " took 47.7741 seconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3q4pwzeYhDPu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}